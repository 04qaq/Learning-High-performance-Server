# epoll学习笔记

## 一、epoll概述

epoll是Linux内核为处理大批量文件描述符（FD）而改进的I/O多路复用机制，是select/poll的增强版本。它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率，特别适合高并发服务器场景（如Nginx、Redis等）。

## 二、核心机制

epoll主要由**用户态系统调用**和**内核态关键数据结构**组成：

### 1. 用户态系统调用
epoll提供三个核心系统调用：

| 系统调用                       | 作用                               | 说明                                         |
| ------------------------------ | ---------------------------------- | -------------------------------------------- |
| `epoll_create`/`epoll_create1` | 创建epoll实例，返回epoll文件描述符 | `size`参数在Linux 2.6.8后已废弃，但必须大于0 |
| `epoll_ctl`                    | 添加/修改/删除监控的文件描述符     | 用于注册感兴趣的事件类型                     |
| `epoll_wait`                   | 等待I/O事件发生                    | 阻塞等待，返回就绪的事件                     |

### 2. 内核态关键数据结构
内核中主要维护以下数据结构：

- **红黑树（RB-Tree）**：存储所有被`epoll_ctl`注册的文件描述符（fd），提供O(log n)的插入、删除和查找性能
- **就绪列表（Ready List）**：存储已经就绪的fd，当fd上发生I/O事件时，内核会将其添加到该列表
- **回调机制**：为每个fd注册回调函数，当fd状态变化时触发

> 内核中**没有**"等待队列"这个结构。当socket有数据到达时，内核通过socket的等待队列（wait queue）唤醒epoll线程，而不是将数据放入"等待队列"。

## 三、epoll工作流程

### 1. 创建epoll实例
```c
int epfd = epoll_create1(0);  // Linux 2.6.8后推荐使用epoll_create1
```
- 内核创建`struct eventpoll`对象，包含红黑树和就绪列表
- 返回epoll文件描述符`epfd`

### 2. 注册事件（epoll_ctl）
```c
struct epoll_event event;
event.events = EPOLLIN;  // 监听可读事件
event.data.fd = sockfd;
epoll_ctl(epfd, EPOLL_CTL_ADD, sockfd, &event);
```
- 将fd插入到红黑树中
- 为该fd注册回调函数（当socket事件发生时，回调函数会将fd添加到就绪列表）

### 3. 等待事件（epoll_wait）
```c
struct epoll_event events[10];
int nfds = epoll_wait(epfd, events, 10, -1);
```
- 内核检查就绪列表，如果为空则阻塞（休眠）
- 有事件时，将就绪列表中的事件复制到用户空间
- 返回就绪事件数量

## 四、epoll高效的原因

epoll相比select/poll的高效性主要体现在三个方面：

### 1. 数据结构优化
- **红黑树替代线性结构**：select/poll使用线性结构（数组/链表）管理fd，时间复杂度O(n)；epoll使用红黑树，时间复杂度O(log n)
- **就绪列表**：epoll_wait只需遍历就绪列表，时间复杂度O(1)，而select/poll需要遍历所有fd

### 2. 事件驱动机制
- **回调机制**：内核在fd状态变化时主动通知（通过回调函数），而不是轮询
- **避免无意义检查**：epoll只关注"活跃"的fd，而select/poll每次调用都会检查所有fd
- **事件通知**：当fd就绪时，内核直接将其加入就绪列表，用户空间程序只需从就绪列表获取

### 3. 内核与用户空间交互优化
- **减少数据拷贝**：epoll只在注册fd时拷贝一次，而select/poll每次调用都要拷贝整个fd集合
- **mmap加速**：epoll通过mmap将内核空间和用户空间映射到同一块内存，避免数据拷贝
- **系统调用优化**：epoll只需3次系统调用（创建、注册、等待），而select/poll每次都要传递整个fd集合

> **性能对比**：假设有10万个连接，但只有10个活跃
>
> - select/poll：每次调用需检查10万个fd，时间复杂度O(100,000)
> - epoll：只返回10个活跃fd，时间复杂度O(1)

## 五、epoll的工作模式

epoll支持两种事件触发模式：

| 模式                           | 说明                                                       | 适用场景                | 优势                       | 缺点                                       |
| ------------------------------ | ---------------------------------------------------------- | ----------------------- | -------------------------- | ------------------------------------------ |
| **LT (Level Triggered, 默认)** | 只要fd处于就绪状态（如可读），epoll_wait就会不断返回该事件 | 传统select/poll兼容模式 | 编程简单，不易出错         | 事件可能被重复触发                         |
| **ET (Edge Triggered)**        | 仅在fd状态变化时触发一次事件（如从无数据变为有数据）       | 高性能场景              | 减少事件触发次数，性能更高 | 需要一次性处理完所有数据，否则可能丢失事件 |

>  **ET模式使用要点**：
> - 仅支持非阻塞socket
> - 必须在事件触发后一次性处理完所有数据
> - 需要处理EAGAIN/EWOULDBLOCK错误

## 六、epoll的典型应用场景

1. **高并发服务器**：如Nginx、Redis、Memcached等
2. **网络代理**：如HAProxy、Squid
3. **即时通讯**：如微信、QQ等IM系统
4. **负载均衡器**：处理大量并发连接的负载均衡

## 七、epoll与select/poll的对比

| 特性         | select             | poll               | epoll                              |
| ------------ | ------------------ | ------------------ | ---------------------------------- |
| 最大连接数   | 通常1024           | 理论无上限         | 理论无上限（受系统文件描述符限制） |
| 事件检测机制 | 轮询 O(N)          | 轮询 O(N)          | 事件驱动 O(1)                      |
| 数据拷贝     | 每次调用复制fd列表 | 每次调用复制fd列表 | 仅注册时复制一次                   |
| 工作模式     | 仅支持LT           | 仅支持LT           | 支持LT和ET                         |
| 适用场景     | 少量连接           | 中等量连接         | 万级以上的并发连接                 |

## 八、常见误区澄清

1. **"size参数在epoll_create中很重要"**：错误。size参数在Linux 2.6.8后已被废弃，内核会忽略它，只需大于0即可。

2. **"epoll有等待队列"**：错误。epoll本身没有"等待队列"，而是socket有等待队列（wait queue）用于唤醒epoll线程。

3. **"epoll会将数据放入就绪队列"**：错误。就绪队列存储的是**已经就绪的文件描述符**，而不是数据本身。

4. **"epoll适合所有场景"**：不完全正确。当所有fd都活跃时（如高速LAN环境），epoll性能并不比select/poll好，甚至可能略差。

## 九、总结

epoll之所以高效，是因为它：
1. 使用红黑树管理fd，提供O(log n)的增删查改效率
2. 采用事件驱动机制，通过回调函数将就绪事件加入就绪列表
3. 通过mmap实现内核与用户空间的高效数据传递
4. 支持LT和ET两种工作模式，灵活适应不同场景

在高并发、只有少量活跃连接的场景下，epoll的性能优势尤为明显，是现代高性能网络服务器的基石技术。